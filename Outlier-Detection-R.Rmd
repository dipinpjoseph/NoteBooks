---
title: "Outlier Detection in R"
author: "Dipin P Joseph"
date: "26/04/2020"
output:

  prettydoc::html_pretty:
    
    theme: cayman
    
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


In this post, we will go through different outlier detection methods and topics like,

* Power Transformation (Yeo Johnson Transform) and Density Plots
* Box Plots and 5 Point Summary Statistics
* Z-Score
* Histograms and Scatter Plots
* Mosaic Plots and Bag Plots
* Mahalanobis Distance
* Cook's Distance
* DBScan 
* Local Outlier Factors
* 1-class Support Vector Machine

Dataset under consideration - **Males** (from package - _Ecdat_)

First, we will explore more about data using __str()__, __summary()__ methods,

```{r message=FALSE}
library(Ecdat)
summary(Males)
str(Males)
```

<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- Notebook Check -->
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-3600373850128255"
     data-ad-slot="2651335722"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>


## Train-Test Split

Here, we will split data to training and testing set. 70% will go for training and 30% for testing.

```{r message=FALSE}
set.seed(7)
# 70% of the sample size
smp_size <- floor(0.7 * nrow(Males))

# Train and Test Split
train_ind <- sample(seq_len(nrow(Males)), size = smp_size)
tr <- Males[train_ind, ]
te <- Males[-train_ind, ]

# Column names split
cols <- colnames(Males)
cols_num <- cols[3:4]
cols_num_all <- c(cols_num, cols[9])
cols_cat <- c(cols[5:8], cols[10:12])
```

## Yeo-Johnson Transformation

Most of the methods will only work well with normalized data. So, we have to transform our variables to another form which are more normally distributed. Yeo-Johnson tansformation will help us here,

```{r message=FALSE}
library(plotly)
library(recipes)

# Performing Yeo Johnson transform for Normalization
# Setting variable price as outcome and remaining numerics as predictors
yj_estimates <-
  recipe(as.formula(paste("wage ~ ", paste(cols_num, collapse = " + "))), data = tr) %>%
  # Power transformation step
  step_YeoJohnson(all_numeric()) %>%
  # Feeds training data
  prep(data = tr)
# The trained process is run of test set
yj_t <- bake(yj_estimates, te)

```

## Density Plot

To display effect of YJ transform density of one variable before and after transformation is plotted.

```{r message=FALSE}
de_b <- density(te$exper)
de_b <- data.frame(x = de_b$x, y = de_b$y)
before <- plot_ly(data = de_b, x = ~ x, y = ~ y)
layout(add_lines(before),
       title = "Density plot of non-transformed variable")
```
```{r message=FALSE}
de_a <- density(yj_t$exper)
de_a <- data.frame(x = de_a$x, y = de_a$y)
after <- plot_ly(data = de_a, x = ~ x, y = ~ y)
layout(add_lines(after),
       title = "Density plot of transformed variable")
```
## Univariate Outlier Detection

## Box Plots

Now, let's plot box plots for numeric variables in the dataset. If you see a datapoint outside the whiskers, then you need to examine that particular observation.

```{r message=FALSE}
bp <- plot_ly(data = yj_t, type = 'box')
for (k in 1:length(cols_num_all)) {
  dfk <- data.frame(y = yj_t[[cols_num_all[k]]])
  bp <-
    add_trace(
      bp,
      y = ~ y,
      data = dfk,
      name = cols_num_all[k],
      notched = TRUE,
      text =  ~ y
    )
}

layout(bp,
       yaxis = list(title = "Value"))
```



## Five Number Summary

Boxplots are created on basis of 5 number summary. This includes,

* Minimum
* Q1 - 25%
* Median
* Q3 - 75%
* Maximum

Let's detect 5 number summary for variable __wages__,

```{r message=FALSE}
fnum = (fivenum(yj_t$wage))
print(fnum)
# Calculating end point of whiskers
low = fnum[2] - 1.5 * (fnum[4] - fnum[2])
high = fnum[4] + 1.5 * (fnum[4] - fnum[2])
print(paste("Outliers are outside region", low, high))
```

## Histogram

 A histogram is a frequency distribution of given data. It's major purpose here is to get a visual idea about skewness, range, value distribution of each numeric variable. Histogram for __wage__ be like,
 
```{r message=FALSE}
hist <- plot_ly(data = te,
                x = ~ wage,
                type = "histogram")

layout(hist,
       xaxis = list(title = "wage"),
       margin = list(t = 80))
```
 
## Z-Score

Z-score is a measure of relationship between an observation with mean and standard deviation of group of observations. Usually, a z-score outside (-3,+3) is considered as a novelty. Outliers found for __wage__ using Z Score is as follows,

```{r message=FALSE}
rows_w <- c()
dfk <- scale(yj_t$wage)
for (i in 1:length(dfk)) {
  if (dfk[i] > 3 | dfk[i] < -3) {
    rows_w = c(rows_w, i)
  }
}
te[rows_w,]
```

<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- Notebook Check -->
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-3600373850128255"
     data-ad-slot="2651335722"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>

## Bivariate Outlier Detection

Now onwards we will see how to identify outliers when 2 or more variables are combined,

## Sactter Plot

From the scatter plot one can manually identify outliers by considering two vairables. Let's plot for variables __school__ and __exper__,

```{r message=FALSE}
h_dat = paste("Obs No :",
              rownames(te))
sc <-
  plot_ly(
    data = yj_t,
    x = ~school,
    y = ~exper,
    hover_data = 'text',
    text = h_dat
  )
layout(sc,
       yaxis = list(title = "school"),
       xaxis = list(title = "exper")
)
```

## Bag Plot

 Bag plot is an improved version of box plot capable of finding outliers in 2/3 dimension data. Using package aplpack::bagplot, it was possible to visualize and fetch outliers in selected variables. 
 
```{r message=FALSE} 
library(aplpack)
bagplot(yj_t$school, yj_t$exper)
```
